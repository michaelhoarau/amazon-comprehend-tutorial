{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom entity recognition with Comprehend\n",
    "---\n",
    "*Step 3: request inferences from both the predefined and the custom models*\n",
    "\n",
    "This series of notebook is a walkthrough on how to leverage Amazon Comprehend to recognize customized entities from documents. More details about the training process can be found here: https://docs.aws.amazon.com/comprehend/latest/dg/training-recognizers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip -q install --upgrade pip\n",
    "pip -q install sagemaker awscli boto3 --upgrade\n",
    "pip -q install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'comprehend_workshop/inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('M. Paul  MARTIN, un bon chrétien, est actuellement malade et a un cancer à ce '\n",
    "        'titre je ne lui accorderai jamais le produit demandé. De plus c’est un hypocrite '\n",
    "        'et n’ai aucune confiance en ce membre du parti LR. Traitement des métastases '\n",
    "        'hépatiques des cancers colorectaux : jusqu\\'où aller ? Les patients qui ne sont pas '\n",
    "        'en mesure d ’ avaler des comprimés devraient utiliser la solution orale , ou alors '\n",
    "        'ils peuvent écraser les comprimés et les mélanger à une petite quantité de nourriture '\n",
    "        'ou de boisson , avant de prendre la dose immédiatement. Numéro de téléphone: +33 060 708 101')\n",
    "\n",
    "with open('test.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_client    = boto3.client('comprehendmedical')\n",
    "comprehend_client = boto3.client('comprehend')\n",
    "translate_client  = boto3.client('translate')\n",
    "s3                = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: applying Amazon Comprehend in French\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fr = comprehend_client.detect_entities(\n",
    "    Text=text,\n",
    "    LanguageCode='fr'\n",
    ")\n",
    "pd.DataFrame(response_fr['Entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: translating content in English\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = translate_client.translate_text(\n",
    "    Text=text,\n",
    "    SourceLanguageCode='auto',\n",
    "    TargetLanguageCode='en'\n",
    ")\n",
    "translation = response['TranslatedText']\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: extracting entities, PII, and medical entities\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_en = comprehend_client.detect_entities(\n",
    "    Text=translation,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "pd.DataFrame(response_en['Entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_pii_en = comprehend_client.detect_pii_entities(\n",
    "    Text=text,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "pd.DataFrame(response_pii_en['Entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_en_med = medical_client.detect_entities_v2(\n",
    "    Text=translation\n",
    ")\n",
    "pd.DataFrame(response_en_med['Entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: leverage custom entities in French\n",
    "---\n",
    "Before you start make sure that your Sagemaker Execution Role has the right credentials (see initial notebooks for IAM configuration).\n",
    "\n",
    "The following yields the properties of the available entity recognizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.list_entity_recognizers(\n",
    "    Filter={\n",
    "        'Status': 'TRAINED',\n",
    "    },\n",
    ")\n",
    "\n",
    "print(len(response['EntityRecognizerPropertiesList']), 'trained model(s) found')\n",
    "model_arn = response['EntityRecognizerPropertiesList'][0]['EntityRecognizerArn']\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 - Using a realtime endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.create_endpoint(\n",
    "    EndpointName='FrenchMedicalEntityRekognizer',\n",
    "    ModelArn=model_arn,\n",
    "    DesiredInferenceUnits=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_arn = response['EndpointArn']\n",
    "status_response = comprehend_client.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "status = status_response['EndpointProperties']['Status']\n",
    "\n",
    "while status in ['CREATING']:\n",
    "    status_response = comprehend_client.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "    status = status_response['EndpointProperties']['Status']\n",
    "    print(status)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fr_med = comprehend_client.detect_entities(\n",
    "    Text=text,\n",
    "    LanguageCode='fr',\n",
    "    EndpointArn=endpoint_arn\n",
    ")\n",
    "pd.DataFrame(response_fr_med['Entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fr = []\n",
    "for e in response_fr['Entities']:\n",
    "    data_fr.append({\n",
    "        'start': e['BeginOffset'],\n",
    "        'end': e['EndOffset'],\n",
    "        'label': e['Type']\n",
    "    })\n",
    "    \n",
    "for e in response_fr_med['Entities']:\n",
    "    data_fr.append({\n",
    "        'start': e['BeginOffset'],\n",
    "        'end': e['EndOffset'],\n",
    "        'label': e['Type']\n",
    "    })\n",
    "    \n",
    "data_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(\n",
    "    docs={'text': text, 'ents': data_fr, 'title': 'Document traité en français'}, \n",
    "    style='ent', \n",
    "    jupyter=True, \n",
    "    manual=True, \n",
    "    options={\n",
    "        'colors': {\n",
    "            'DISORDERS': '#A6E22D',\n",
    "            'CHEMICALS': '#EF60B5',\n",
    "            'PROCEDURE': '#43C8FF',\n",
    "            'LIVING_BEING': '#A99DFB',\n",
    "            'ANATOMY': '#FFCC00',\n",
    "            'PHYSIOLOGY': '#2FBCAC',\n",
    "            'OTHER': '#EF60B5',\n",
    "            'ORGANIZATION': '#2FBCAC',\n",
    "            'QUANTITY': '#FFCC00',\n",
    "            'NAME': '#A99DFB',\n",
    "            'GENERIC_NAME': '#A99DFB',\n",
    "            'DX_NAME': '#EF60B5',\n",
    "            'SYSTEM_ORGAN_SITE': '#FFCC00'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 - Using a realtime endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.meta.client.upload_file('test.txt', bucket, prefix + '/test.txt')\n",
    "\n",
    "response = comprehend_client.start_entities_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://{}/{}/test.txt'.format(bucket, prefix),\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    JobName='GetFrenchMedicalEntitiesV2',\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://{}/comprehend_data/output_v2/'.format(bucket),\n",
    "    },\n",
    "    DataAccessRoleArn='arn:aws:iam::123031033346:role/service-role/AmazonComprehendServiceRole-FrenchMedicalEntities',\n",
    "    EntityRecognizerArn=model_arn #'arn:aws:comprehend:eu-west-1:123031033346:entity-recognizer/FrenchMedicalEntities-v2',\n",
    "    LanguageCode='en', # This is ignored for the custom entities recognition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobId = response['JobId']\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_job = comprehend_client.describe_entities_detection_job(JobId=jobId)\n",
    "    status = describe_job[\"EntitiesDetectionJobProperties\"][\"JobStatus\"]\n",
    "    print(\"Job Status: {}\".format(status))\n",
    "    \n",
    "    if status == \"COMPLETED\" or status == \"FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the test output to local machine\n",
    "describe_job = comprehend_client.describe_entities_detection_job(JobId = response['JobId'])\n",
    "job_output = describe_job[\"EntitiesDetectionJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket)\n",
    "job_key = os.path.relpath(job_output, path_prefix)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_key, 'output.tar.gz')\n",
    "\n",
    "!tar xvzf output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all the Entities values in a list\n",
    "data_fr = []\n",
    "for line in open('output-v2', 'r'):\n",
    "    entities = json.loads(line)['Entities']\n",
    "    if entities != None and len(entities) > 0:\n",
    "        for e in entities:\n",
    "            data_fr.append({\n",
    "                'start': e['BeginOffset'],\n",
    "                'end': e['EndOffset'],\n",
    "                'label': e['Type']\n",
    "            })\n",
    "    \n",
    "for e in response_fr['Entities']:\n",
    "    data_fr.append({\n",
    "        'start': e['BeginOffset'],\n",
    "        'end': e['EndOffset'],\n",
    "        'label': e['Type']\n",
    "    })    \n",
    "\n",
    "data_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = []\n",
    "for e in response_en['Entities']:\n",
    "    data_en.append({\n",
    "        'start': e['BeginOffset'],\n",
    "        'end': e['EndOffset'],\n",
    "        'label': e['Type']\n",
    "    })\n",
    "    \n",
    "for e in response_en_med['Entities']:\n",
    "    data_en.append({\n",
    "        'start': e['BeginOffset'],\n",
    "        'end': e['EndOffset'],\n",
    "        'label': e['Type']\n",
    "    })\n",
    "\n",
    "    \n",
    "data_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(\n",
    "    docs={'text': text, 'ents': data_fr, 'title': 'Traitement du Français'}, \n",
    "    style='ent', \n",
    "    jupyter=True, \n",
    "    manual=True, \n",
    "    options={\n",
    "        'colors': {\n",
    "            'DISORDERS': '#A6E22D',\n",
    "            'CHEMICALS': '#EF60B5',\n",
    "            'PROCEDURE': '#43C8FF',\n",
    "            'LIVING_BEING': '#A99DFB',\n",
    "            'ANATOMY': '#FFCC00',\n",
    "            'PHYSIOLOGY': '#2FBCAC',\n",
    "            'OTHER': '#EF60B5',\n",
    "            'ORGANIZATION': '#2FBCAC',\n",
    "            'QUANTITY': '#FFCC00'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(\n",
    "    docs={'text': translation, 'ents': data_en, 'title': 'Après traduction en anglais'}, \n",
    "    style='ent', \n",
    "    jupyter=True, \n",
    "    manual=True, \n",
    "    options={\n",
    "        'colors': {\n",
    "            'DISORDERS': '#A6E22D',\n",
    "            'CHEMICALS': '#EF60B5',\n",
    "            'PROCEDURE': '#43C8FF',\n",
    "            'LIVING_BEING': '#A99DFB',\n",
    "            'ANATOMY': '#FFCC00',\n",
    "            'PHYSIOLOGY': '#2FBCAC',\n",
    "            'OTHER': '#EF60B5',\n",
    "            'ORGANIZATION': '#2FBCAC',\n",
    "            'QUANTITY': '#FFCC00',\n",
    "            'NAME': '#A99DFB',\n",
    "            'GENERIC_NAME': '#A99DFB',\n",
    "            'DX_NAME': '#EF60B5',\n",
    "            'SYSTEM_ORGAN_SITE': '#FFCC00'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
